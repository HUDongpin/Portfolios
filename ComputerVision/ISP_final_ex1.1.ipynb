{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. using the package management tool pip to install the necessary modules for running the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: opencv-python in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. import dependencies for exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Background subtraction \n",
    "\n",
    "First, create a VideoCapture object and read the frames from an input file. The first captured frame is regarded as the baseline image. \n",
    "\n",
    "Second, calculate the difference between the baseline and the gray frame.\n",
    "\n",
    "Third, the difference frame named delta_frame is converted into a binary image which will be compared with a certain threshold (50), if it is greater than the threshold, it will be assigned the value of white (255), else it will be assigned the value of black (0).\n",
    "\n",
    "Fourth, identify all the contours in the image and filter out small contours that do not belong to a car shape. Then draw green rectangles to highlight car shapes and draw red lines to indicate the main street area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a VideoCapture object and read the frames from an input file\n",
    "video = cv2.VideoCapture('Traffic_Laramie_1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the video is opened successfully, if not, print error message\n",
    "if (video.isOpened()== False): \n",
    "    print(\"Error opening video file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the value of initial frame as None\n",
    "initial_frame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1040)\n"
     ]
    }
   ],
   "source": [
    "# read through the video frame until video is completed or the user press 'q'\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    # breaks when reaching the end of the file \n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # gray conversion: convert an image from one color space to another\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # the first captured frame is regarded as the baseline image\n",
    "    if initial_frame is None:\n",
    "        initial_frame = gray_frame\n",
    "        print(initial_frame.shape)\n",
    "        continue\n",
    "\n",
    "    # frame differencing: calculate the difference between the baseline and the gray frame\n",
    "    delta_frame = cv2.absdiff(initial_frame,gray_frame)\n",
    "    \n",
    "    \n",
    "    # the difference (the delta_frame) is converted into a binary image\n",
    "    # if a particular pixel value is greater than a certain threshold (50)\n",
    "    # if it is greater than the threshold, it will be assigned the value of white (255)\n",
    "    # else it will be assigned the value of black (0)\n",
    "    threshold_frame = cv2.threshold(delta_frame,50,255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    blur_frame = cv2.GaussianBlur(threshold_frame,(25,25),0)\n",
    "    \n",
    "    # identify all the contours in the image\n",
    "    # this method has THREE parameters, (a) image, (b) contour retrieval mode and # (c) contour approximation method\n",
    "    (contours,_) = cv2.findContours(blur_frame,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        # filter out any small contours that do not belong to a car shape\n",
    "        if cv2.contourArea(c) < 6900:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # draw green rectangles to highlight car shapes\n",
    "        if y > 260:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 1)\n",
    "            \n",
    "        # draw the red line which indicates the main street area by cv2.line() method \n",
    "        # this is a horiontal line\n",
    "        x1, y1 = 0, 260\n",
    "        x2, y2 = 1040, 260\n",
    "        \n",
    "        # initialise the value of line thickness as 3\n",
    "        line_thickness = 3\n",
    "        \n",
    "        # NOTE: color is in BGR, e.g., (0, 0, 255) means red\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), thickness=line_thickness)\n",
    "        \n",
    "        # display the image\n",
    "        cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # stop the program by pressing 'q'    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the loop above, release the video object\n",
    "video.release()\n",
    "\n",
    "# and destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Improvements for Exercise 1.1 and 1.2\n",
    "\n",
    "In the previous part, the first captured frame (initial frame) is regarded as the baseline image (i.e., background frame). In the method cv2.absdiff(), the difference between the baseline and the gray frame is calculated. Thus, I recommend using median frame as the background frame instead of initial frame in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function named median_frame with one parameter named path\n",
    "def median_frame(path):\n",
    "    \n",
    "    # creage a VideoCapture object and read the frames from an input file with a given path\n",
    "    video = cv2.VideoCapture(path)\n",
    "    \n",
    "    # generate 50 indexes based on 50 random frames for median\n",
    "    indexes = video.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    \n",
    "    # initialise an empty array to store frames\n",
    "    frames = []\n",
    "    \n",
    "    # iterate each index and read video frame\n",
    "    for i in indexes:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        check, frame = video.read()\n",
    "        frames.append(frame)\n",
    "        \n",
    "    # calculate the median of 50 random frames\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    \n",
    "    # the function returns the median frame\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function backgroundDetection has the same function to the part 3 code. In other words, the function backgroundDetection can also detect and track moving cars in the video recording. In addition, the function backgroundDetection has its additional function, which is to return the value for number of cars go into city center. The value of num_car_into_city_center will be used for exercise 1.2 to calculate the value of cars per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function named backgroundDetection with three parameters\n",
    "def backgroundDetection(path, numframes, rect_loc):\n",
    "    \n",
    "    # creage a VideoCapture object and read the frames from an input file with a given path\n",
    "    video = cv2.VideoCapture(path)\n",
    "\n",
    "    # get the height of the frame which detect cars at the main street only\n",
    "    height = int(video.get(4))\n",
    "\n",
    "    # get the median frame as the background frame based on the aforementioned function named median_frame\n",
    "    background = median_frame(path)\n",
    "    \n",
    "    # convert the background frame in gray scale\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # initialise the count as the value of 0\n",
    "    count = 0\n",
    "    \n",
    "    # initialise the numframes as the same value to parameter numframes\n",
    "    numframes = numframes\n",
    "\n",
    "    # initiaise the number of cars go into city center as the value of 0\n",
    "    num_car_into_city_center = 0\n",
    "    \n",
    "    # create two empty arrays to store the x and y locations of the previous and current rectangles\n",
    "    current_rect = []\n",
    "    previous_rect = []\n",
    "    \n",
    "    # read through the video frame until video is completed or the user press 'q'\n",
    "    while (video.isOpened()):\n",
    "        check, frame = video.read()\n",
    "        if check == True:\n",
    "            count += 1\n",
    "            \n",
    "            # make a copy of the original frame\n",
    "            original_frame = frame.copy()\n",
    "            \n",
    "            # convert frame to grayscale\n",
    "            gray_scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # checks whether frame count has reached a multiple of numframes\n",
    "            if count % numframes == 0 or count == 1:\n",
    "                difference_array = []\n",
    "                \n",
    "            # calculates absolute difference between gray scale and background\n",
    "            abs_diff = cv2.absdiff(gray_scale, background)\n",
    "            \n",
    "            # converts the difference to binary using thresholding\n",
    "            check, thres = cv2.threshold(abs_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # enlarge frame to increase contour detection\n",
    "            enlarge_frame = cv2.dilate(thres, None, iterations=2)\n",
    "            \n",
    "            # append the final result into the array named difference_array\n",
    "            difference_array.append(enlarge_frame)\n",
    "            \n",
    "            # check if difference_array has reached the required length\n",
    "            \n",
    "            if len(difference_array) == numframes:\n",
    "                # calculate the sum the frames in the difference_array\n",
    "                sum_num_frames = sum(difference_array)\n",
    "                \n",
    "                # save contours around the white enlarged areas\n",
    "                contours, hierarchy = cv2.findContours(sum_num_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # iterate every contour\n",
    "                for i in range(len(contours)):\n",
    "                    \n",
    "                    # filter out any small contours that does not belong to a car shape\n",
    "                    if cv2.contourArea(contours[i]) < 500:\n",
    "                        continue\n",
    "                    (x, y, w, h) = cv2.boundingRect(contours[i])\n",
    "\n",
    "\n",
    "                    # draw green rectangles to highlight car shapes\n",
    "                    if y > height / 2 and w * h > 6000:\n",
    "                        cv2.rectangle(original_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                        \n",
    "                        # append the locations of the rectangles to an array named current_rect\n",
    "                        current_rect.append((x, y, w, h))\n",
    "\n",
    "                # find the minimum length of the previous and current array of rectangles\n",
    "                min_len = min(len(current_rect), len(previous_rect))\n",
    "                for i in range(min_len):\n",
    "                    if current_rect[i][0] > 400 and current_rect[i][0] < rect_loc and current_rect[i][1] > 350 and current_rect[i][1] < 400 and current_rect[i][0] < previous_rect[i][0]:\n",
    "                        \n",
    "                        # calculate the number of cars go into the city center\n",
    "                        num_car_into_city_center += 1\n",
    "                        \n",
    "                        # print current number of cars go into the city center\n",
    "                        print(num_car_into_city_center)\n",
    "\n",
    "                # set the previous array of rectangles equal to the current array of rectangles\n",
    "                previous_rect = current_rect\n",
    "                \n",
    "                # reset current array of rectangles\n",
    "                current_rect = []\n",
    "\n",
    "                # display the image\n",
    "                cv2.imshow('Detected Objects', original_frame)\n",
    "                \n",
    "                # detect key event every 100ms , if the user press 'q', then stop the program \n",
    "                if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    # after the loop above, release the video object\n",
    "    video.release()\n",
    "    \n",
    "    # and destroy all windows\n",
    "    cv2.destroyAllWindows() \n",
    "    \n",
    "    # return the value for number of cars go into city center \n",
    "    return num_car_into_city_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# get the value for numbers of cars go into city center on video 1 \n",
    "num_car_into_city_center_1 = backgroundDetection('Traffic_Laramie_1.mp4', 4, 435)\n",
    "\n",
    "# get the value for numbers of cars go into city center on video 2\n",
    "num_car_into_city_center_2 = backgroundDetection('Traffic_Laramie_2.mp4', 5, 440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "\n",
    "arindomjit GitHub (2021). Motion_Detected_Alarm. Retrieved February 5, 2023,https://github.com/arindomjit/Motion_Detected_Alarm\n",
    "\n",
    "Coursera. (n.d.).7.104 Exercise 15: Introduction to motion detection with OpenCV and Python. Retrieved February 5, 2023, from https://www.coursera.org/learn/uol-cm3065-intelligent-signal-processing/ungradedLab/0PXRU/7-104-exercise-15-introduction-to-motion-detection-with-opencv-and-python/lab?path=%2Fnotebooks%2FExercises%2FExercise%252015.%2520Introduction%2520to%2520motion%2520detection%2520with%2520OpenCV%2520and%2520Python.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
