{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f335998c",
   "metadata": {},
   "source": [
    "Install required module by the package management tool pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9acd46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (1.21.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (2.28.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (2.19.3)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (0.4.8)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from imageio<3.0,>=2.5->moviepy) (9.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Peterhu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e22d5",
   "metadata": {},
   "source": [
    "5. import dependencies for exercise 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d570ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857629a5",
   "metadata": {},
   "source": [
    "6. Improvements for Exercise 1.1 and 1.2\n",
    "\n",
    "In the previous part, the first captured frame (initial frame) is regarded as the baseline image (i.e., background frame). In the method cv2.absdiff(), the difference between the baseline and the gray frame is calculated. Thus, I recommend using median frame as the background frame instead of initial frame in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c171d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function named median_frame with one parameter named path\n",
    "def median_frame(path):\n",
    "    \n",
    "    # creage a VideoCapture object and read the frames from an input file with a given path\n",
    "    video = cv2.VideoCapture(path)\n",
    "    \n",
    "    # generate 50 indexes based on 50 random frames for median\n",
    "    indexes = video.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    \n",
    "    # initialise an empty array to store frames\n",
    "    frames = []\n",
    "    \n",
    "    # iterate each index and read video frame\n",
    "    for i in indexes:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        check, frame = video.read()\n",
    "        # append new frame to an array named frames\n",
    "        frames.append(frame)\n",
    "        \n",
    "    # calculate the median of 50 random frames\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    \n",
    "    # the function returns the median frame\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38266340",
   "metadata": {},
   "source": [
    "The function backgroundDetection has the same function to the part 3 code. In other words, the function backgroundDetection can also detect and track moving cars in the video recording. In addition, the function backgroundDetection has its additional function, which is to return the value for number of cars go into city center. The value of num_car_into_city_center will be used for exercise 1.2 to calculate the value of cars per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2973e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function named backgroundDetection with three parameters\n",
    "def backgroundDetection(path, numframes, rect_loc):\n",
    "    \n",
    "    # creage a VideoCapture object and read the frames from an input file with a given path\n",
    "    video = cv2.VideoCapture(path)\n",
    "\n",
    "    # get the height of the frame which detect cars at the main street only\n",
    "    height = int(video.get(4))\n",
    "\n",
    "    # get the median frame as the background frame based on the aforementioned function named median_frame\n",
    "    background = median_frame(path)\n",
    "    \n",
    "    # convert the background frame in gray scale\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # initialise the count as the value of 0\n",
    "    count = 0\n",
    "    \n",
    "    # initialise the numframes as the same value to parameter numframes\n",
    "    numframes = numframes\n",
    "\n",
    "    # initiaise the number of cars go into city center as the value of 0\n",
    "    num_car_into_city_center = 0\n",
    "    \n",
    "    # create two empty arrays to store the x and y locations of the previous and current rectangles\n",
    "    current_rect = []\n",
    "    previous_rect = []\n",
    "    \n",
    "    # read through the video frame until video is completed or the user press 'q'\n",
    "    while (video.isOpened()):\n",
    "        check, frame = video.read()\n",
    "        if check == True:\n",
    "            count += 1\n",
    "            \n",
    "            # make a copy of the original frame\n",
    "            original_frame = frame.copy()\n",
    "            \n",
    "            # convert frame to grayscale\n",
    "            gray_scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # checks whether frame count has reached a multiple of numframes\n",
    "            if count % numframes == 0 or count == 1:\n",
    "                difference_array = []\n",
    "                \n",
    "            # calculates absolute difference between gray scale and background\n",
    "            abs_diff = cv2.absdiff(gray_scale, background)\n",
    "            \n",
    "            # converts the difference to binary using thresholding\n",
    "            check, thres = cv2.threshold(abs_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # enlarge frame to increase contour detection\n",
    "            enlarge_frame = cv2.dilate(thres, None, iterations=2)\n",
    "            \n",
    "            # append the final result into the array named difference_array\n",
    "            difference_array.append(enlarge_frame)\n",
    "            \n",
    "            # check if difference_array has reached the required length\n",
    "            \n",
    "            if len(difference_array) == numframes:\n",
    "                # calculate the sum the frames in the difference_array\n",
    "                sum_num_frames = sum(difference_array)\n",
    "                \n",
    "                # save contours around the white enlarged areas\n",
    "                contours, hierarchy = cv2.findContours(sum_num_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # iterate every contour\n",
    "                for i in range(len(contours)):\n",
    "                    \n",
    "                    # filter out any small contours that does not belong to a car shape\n",
    "                    if cv2.contourArea(contours[i]) < 500:\n",
    "                        continue\n",
    "                    (x, y, w, h) = cv2.boundingRect(contours[i])\n",
    "\n",
    "\n",
    "                    # draw green rectangles to highlight car shapes\n",
    "                    if y > height / 2 and w * h > 6000:\n",
    "                        cv2.rectangle(original_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                        \n",
    "                        # append the locations of the rectangles to an array named current_rect\n",
    "                        current_rect.append((x, y, w, h))\n",
    "\n",
    "                # find the minimum length of the previous and current array of rectangles\n",
    "                min_len = min(len(current_rect), len(previous_rect))\n",
    "                for i in range(min_len):\n",
    "                    if current_rect[i][0] > 400 and current_rect[i][0] < rect_loc and current_rect[i][1] > 350 and current_rect[i][1] < 400 and current_rect[i][0] < previous_rect[i][0]:\n",
    "                        \n",
    "                        # calculate the number of cars go into the city center\n",
    "                        num_car_into_city_center += 1\n",
    "                        \n",
    "                        # print current number of cars go into the city center\n",
    "                        print(num_car_into_city_center)\n",
    "\n",
    "                # set the previous array of rectangles equal to the current array of rectangles\n",
    "                previous_rect = current_rect\n",
    "                \n",
    "                # reset current array of rectangles\n",
    "                current_rect = []\n",
    "\n",
    "                # display the image\n",
    "                cv2.imshow('Detected Objects', original_frame)\n",
    "                \n",
    "                # detect key event every 100ms , if the user press 'q', then stop the program \n",
    "                if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    # after the loop above, release the video object\n",
    "    video.release()\n",
    "    \n",
    "    # and destroy all windows\n",
    "    cv2.destroyAllWindows() \n",
    "    \n",
    "    # return the value for number of cars go into city center \n",
    "    return num_car_into_city_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f92558",
   "metadata": {},
   "source": [
    "7. calculate **Total number of cars** and **Cars per minute** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5820fb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# get the value for numbers of cars go into city center on video 1 \n",
    "num_car_into_city_center_1 = backgroundDetection('Traffic_Laramie_1.mp4', 4, 435)\n",
    "\n",
    "# get the value for numbers of cars go into city center on video 2\n",
    "num_car_into_city_center_2 = backgroundDetection('Traffic_Laramie_2.mp4', 5, 440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcb1ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.92000000000002\n"
     ]
    }
   ],
   "source": [
    "# load the first video by VideoFileClip method\n",
    "video1 = VideoFileClip('Traffic_Laramie_1.mp4')\n",
    "\n",
    "# calculate the first video duration in seconds and print the result\n",
    "video1_duration_in_seconds = video1.duration\n",
    "\n",
    "print(video1_duration_in_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aadaef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9653333333333336\n"
     ]
    }
   ],
   "source": [
    "# calculate the first video duration in minutes and print the result\n",
    "video1_duration_in_minutes = video1_duration_in_seconds / 60\n",
    "\n",
    "print(video1_duration_in_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34fca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0233812949640284\n"
     ]
    }
   ],
   "source": [
    "# calculate the value of cars per minute on video 1\n",
    "video1_cars_per_minute = num_car_into_city_center_1 / video1_duration_in_minutes\n",
    "\n",
    "print(video1_cars_per_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028e0ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.68\n"
     ]
    }
   ],
   "source": [
    "# load the second video by VideoFileClip method\n",
    "video2 = VideoFileClip('Traffic_Laramie_2.mp4')\n",
    "\n",
    "# calculate the second video duration in seconds and print the result\n",
    "video2_duration_in_seconds = video2.duration\n",
    "\n",
    "print(video2_duration_in_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf29b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7613333333333334\n"
     ]
    }
   ],
   "source": [
    "# calculate the second video duration in minutes and print the result\n",
    "video2_duration_in_minutes = video2_duration_in_seconds / 60\n",
    "\n",
    "print(video2_duration_in_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e10011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.271006813020439\n"
     ]
    }
   ],
   "source": [
    "# calculate the value of cars per minute on video 2\n",
    "video2_cars_per_minute = num_car_into_city_center_2 / video2_duration_in_minutes\n",
    "\n",
    "print(video2_cars_per_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a0a362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Total number of cars</th>\n",
       "      <th>Cars per minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Traffic_Laramie_1.mp4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.023381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic_Laramie_2.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.271007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  Total number of cars  Cars per minute\n",
       "0  Traffic_Laramie_1.mp4                     6         2.023381\n",
       "1  Traffic_Laramie_2.mp4                     4         2.271007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cumulate the required table data and store it as a variable named required_table_data\n",
    "required_table_data = [[\"Traffic_Laramie_1.mp4\", num_car_into_city_center_1, video1_cars_per_minute], \n",
    "                       [\"Traffic_Laramie_2.mp4\", num_car_into_city_center_2, video2_cars_per_minute]]\n",
    "\n",
    "# print the required table as pandas dataframe\n",
    "pd.DataFrame(required_table_data, columns=[\"file\", \"Total number of cars\", \"Cars per minute\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e07ea",
   "metadata": {},
   "source": [
    "Thus, we can fill the following table with the data.\n",
    "                        \n",
    "                        Table 1\n",
    "\n",
    "| **file** | **Total number of cars** | **Cars per minute** |\n",
    "|:----------:|--------------------:|:--------:|\n",
    "| **Traffic_Laramie_1.mp4**     | `6 `            |   2.023381    |\n",
    "| **Traffic_Laramie_2.mp4**     | ` 4`            |  2.271007     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad1a7f",
   "metadata": {},
   "source": [
    "For more details about the application, please read the ISP final report of exercise 1.1 and 1.2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
